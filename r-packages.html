<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>My favourite R packages</title>
    <meta charset="utf-8" />
    <meta name="author" content="Quyu Kong" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
    <script src="libs/jquery-1.12.4/jquery.min.js"></script>
    <script src="libs/d3-3.5.6/d3.min.js"></script>
    <link href="libs/profvis-0.3.6/profvis.css" rel="stylesheet" />
    <script src="libs/profvis-0.3.6/profvis.js"></script>
    <link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
    <script src="libs/highlight-6.2.0/highlight.js"></script>
    <script src="libs/profvis-binding-0.3.6/profvis.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# My favourite R packages
## generated by xaringan
### Quyu Kong
### 2020/03/21

---


# Packages by categories

- Data processing:
  - `data.table` v.s. `tidyverse` (`tibble`, `dplyr`, `readr`, `magrittr`)
  - `purrr`
- Parallel computation:
  - `parallel::mclapply`
  - `future`
  - `furrr`, `future.batchtools`
- Visualization:
  - `ggplot2`, `cowplot`, `patchwork`
  - `shiny`
- Debugging:
  - `profvis`
- Reproducibility:
  - `drake`



---
class: inverse, center, middle

# data.table v.s. tidyverse
## More efficient v.s. better readability
---
# Tidyverse

`magrittr` provides the core of `tidyverse`'s better readability.

```r
x %&gt;% f()
f(x)
```
I found this particularly useful when playing around with data in the console

```r
unique(iris$Species)
```

```
## [1] setosa     versicolor virginica 
## Levels: setosa versicolor virginica
```

```r
unique(iris$Species) %&gt;% length()
```

```
## [1] 3
```

---
# Tidyverse

`tibble` is "a modern reimagining of the data.frame"


```r
iris &lt;- iris %&gt;% as_tibble()
iris %&gt;% print(n=5)
```

```
## # A tibble: 150 x 5
##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  
## 1          5.1         3.5          1.4         0.2 setosa 
## 2          4.9         3            1.4         0.2 setosa 
## 3          4.7         3.2          1.3         0.2 setosa 
## 4          4.6         3.1          1.5         0.2 setosa 
## 5          5           3.6          1.4         0.2 setosa 
## # … with 145 more rows
```

`readr` implements APIs for reading from and writing to files

```r
write_csv(iris, file = 'iris.csv.gz')
read_csv(file = 'iris.csv.gz')
```

---
# Tidyverse

`dplyr` is a grammar of data manipulation.

```r
iris %&gt;%
  filter(Species != 'setosa') %&gt;%
  group_by(Species) %&gt;%
  summarise_all(mean)
```

```
## # A tibble: 2 x 5
##   Species    Sepal.Length Sepal.Width Petal.Length Petal.Width
##   &lt;fct&gt;             &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
## 1 versicolor         5.94        2.77         4.26        1.33
## 2 virginica          6.59        2.97         5.55        2.03
```

Recommended resource: https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf

---
# data.table

`data.table` is another reimplementation of `data.frame` and a data processing grammar designed with efficiency in mind at day 1.
It's basic syntax is

![data.table syntax](https://raw.githubusercontent.com/wiki/Rdatatable/data.table/pictures/syntax1.jpg)

However, this stopped from using `data.table` until I had to switch to it.

---
# data.table
The memory and data processing efficiency of `data.table`:
  - multi-threading processing
  - data processing by reference (the killer feature)
  
---
# data.table

```r
iris_dt &lt;- as.data.table(iris)
iris &lt;- iris %&gt;%
  mutate(Sepal.Width = cut_interval(Sepal.Width, n = 3))
iris_dt[, Sepal.Width := cut_interval(Sepal.Width, n = 3)]
print(iris, n = 3)
```

```
## # A tibble: 150 x 5
##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##          &lt;dbl&gt; &lt;fct&gt;              &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  
## 1          5.1 (2.8,3.6]            1.4         0.2 setosa 
## 2          4.9 (2.8,3.6]            1.4         0.2 setosa 
## 3          4.7 (2.8,3.6]            1.3         0.2 setosa 
## # … with 147 more rows
```

```r
print(iris_dt, n = 3)
```

```
##      Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
##   1:          5.1   (2.8,3.6]          1.4         0.2    setosa
##   2:          4.9   (2.8,3.6]          1.4         0.2    setosa
##   3:          4.7   (2.8,3.6]          1.3         0.2    setosa
##   4:          4.6   (2.8,3.6]          1.5         0.2    setosa
##   5:          5.0   (2.8,3.6]          1.4         0.2    setosa
##  ---                                                            
## 146:          6.7   (2.8,3.6]          5.2         2.3 virginica
## 147:          6.3     [2,2.8]          5.0         1.9 virginica
## 148:          6.5   (2.8,3.6]          5.2         2.0 virginica
## 149:          6.2   (2.8,3.6]          5.4         2.3 virginica
## 150:          5.9   (2.8,3.6]          5.1         1.8 virginica
```

---
# data.table
The file reader and writer from `data.table` also guarantee speed compared to `readr`.

|method   | 	                        max. memory | 	avg. time|
| ------------- |:-------------:| -----:|
|utils::read.csv + base::rbind |	21.70 GB |	8.13 m|
|readr::read_csv + purrr:map_dfr |	27.02 GB |	3.43 m|
|data.table::fread + rbindlist |	15.25 GB |	1.40 m|

More benchmarks: https://h2oai.github.io/db-benchmark/
Recommend reading: https://github.com/Rdatatable/data.table/wiki

---
# purrr from tidyverse

`purrr` is an alternative to R default `apply` function family (`lapply`, `vapply`, etc.). 

```r
iris %&gt;%
  split(.$Species) %&gt;%
  map(~lm(Petal.Length~Petal.Width, data = .x)) %&gt;%
  map('coefficients')
```

```
## $setosa
## (Intercept) Petal.Width 
##   1.3275634   0.5464903 
## 
## $versicolor
## (Intercept) Petal.Width 
##    1.781275    1.869325 
## 
## $virginica
## (Intercept) Petal.Width 
##   4.2406526   0.6472593
```

---
# purrr from tidyverse
To me, one of the most important features is the type consistant API

```r
map_int(1:5, ~.x)
```

```
## [1] 1 2 3 4 5
```

```r
map_chr(letters, ~.x)
```

```
##  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q" "r" "s"
## [20] "t" "u" "v" "w" "x" "y" "z"
```

---
# purrr from tidyverse
Two missing features from `purrr`
  - progress bar (a simple workaround)
  - simple parallelization (where `furrr` comes in)

```r
pb &lt;- progress_estimated(length(files))
map(files, function(f) {
  pb$tick()$print()
  # do something
})
```
  
---
class: inverse, center, middle

# Parallel computation

---
# parallel::mclapply
The `parallel` is a built-in package provided by R that handles concurrent/parallel computing. The typical `makeCluster` by default creates slave R processes and require handling environment.

```r
fxx &lt;- function(x) {x + xx}
xx &lt;- 3
cluster &lt;- makeCluster(2)
clusterExport(cluster, "xx")
parSapply(cl = cluster, X = 1:10, FUN = fxx)
stopCluster(cluster)
```
You can choose to do `makeCluster(2, type = 'fork')`.

---
# parallel::mclapply
I prefer `mclapply` instead due to its simplicity

```r
fxx &lt;- function(x) {x + xx}
xx &lt;- 3
mclapply(X = 1:10, FUN = fxx, mc.cores = 10)
```

---
# parallel::mclapply
Sometimes we need to avoid forking processes due to
  - forking within Rstudio can be problematic
  - might consume more memory when your environment objects are small

---
# future
It provides a unified API interface for different concurrent/paralll computing strategies.

---
# future

```r
v &lt;- {
 cat("Hello world!\n")
 3.14
}
```

```
## Hello world!
```

```r
v
```

```
## [1] 3.14
```

```r
plan(sequential)
v %&lt;-% {
 cat("Hello world!\n")
 3.14
}
v
```

```
## Hello world!
```

```
## [1] 3.14
```

---
# future
| Name            | OSes        | Description
|:----------------|:------------|:-----------------------------------------------------
| _synchronous:_  |             | _non-parallel:_
| `sequential`    | all         | sequentially and in the current R process
| `transparent`   | all         | as sequential w/ early signaling and w/out local (for debugging)
| _asynchronous:_ |             | _parallel_:
| `multiprocess`  | all         | multicore, if supported, otherwise multisession
| `multisession`  | all         | background R sessions (on current machine)
| `multicore`     | not Windows/not RStudio | forked R processes (on current machine)
| `cluster`       | all         | external R sessions on current, local, and/or remote machines
| `remote`        | all         | Simple access to remote R sessions

---
# future
A big advantage of using `multisession` from `future` is the environment handling. The package itself will try to determine what variables are used within the code block then export them to the slave R sessions. This generally works well.

```r
plan(multisession, workers = 2)
Sys.getpid()
```

```
## [1] 14160
```

```r
x &lt;- 1
a %&lt;-% {
  x + 1
  Sys.getpid()
}
a
```

```
## [1] 14218
```

---
# future and furrr
`furrr` is a succinct wrap of `purrr` powered by `future`

```r
iris %&gt;%
  split(.$Species) %&gt;%
  map(~lm(Petal.Length~Petal.Width, data = .x))

plan(multisession)
iris %&gt;%
  split(.$Species) %&gt;%
  future_map(~lm(Petal.Length~Petal.Width, data = .x))
```

---
# future and furrr
If you have multiple remote hosts, `future` allows you to cook on them easily!

```r
plan(remtoe, workers = c('cray', 'dijkstra'))
future_map(c(1, 2), function(task_id) {
  heavy jobs to run on each remote
})
```

---
# future and furrr
You can also have a hierachical plan to detail the resources you need.

```r
plan(list(tweak(remtoe, workers = c('cray', 'dijkstra')),
          tweak(multisession, workers = 40)))
future_map(c(1, 2), function(first_level_task_id) {
  future_map(1:10, function(second_level_task_id) {
    do something here
  })
})

plan(list(tweak(remtoe, workers = c('cray', 'cray', 'dijkstra', 'dijkstra', 'hephaestos')),
          tweak(multisession, workers = 20)))
```

---
# future.batchtools
Additional futures for evaluating R expressions via job schedulers such as Slurm (CSIRO cluster), TORQUE/PBS (NCI), Oracle/Sun Grid Engine and Load Sharing Facility are also available. Not sure which one is UTS cluster using.


---
class: inverse, center, middle

# Other tools

---
# profvis

```r
profvis::profvis({
  get_tweet_id &lt;- function() return(1);
  has_next_tweet &lt;- function(i) i &lt; 10000;
  k &lt;- numeric(); i &lt;- 1;
  while (has_next_tweet(i)) {k &lt;- c(k, get_tweet_id()); i &lt;- i + 1;}
  k &lt;- numeric(); i &lt;- 1;
  while (has_next_tweet(i)) {k[i] &lt;- get_tweet_id(); i &lt;- i + 1;}
})
```

<div id="htmlwidget-fedab368116483fe4df9" style="width:100%;height:600px;" class="profvis html-widget"></div>
<script type="application/json" data-for="htmlwidget-fedab368116483fe4df9">{"x":{"message":{"prof":{"time":[1,2,3,4,5,5,6,7,8,9,10,11,12,12,13,14,15,16,17,18,19,19,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21],"depth":[1,1,1,1,2,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,2,1,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1],"label":["c","c","c","c","<GC>","c","while (has_next_tweet(i)) {k <- c(k, get_tweet_id()); i <- i + 1;}","c","while (has_next_tweet(i)) {k <- c(k, get_tweet_id()); i <- i + 1;}","c","c","c","<GC>","c","c","c","c","c","c","c","<GC>","c","c","cb$putconst","cmpCallArgs","cmpCallSymFun","cmpCall","cmp","cmpWhileBody","h","tryInline","cmpCall","cmp","genCode","compile","doTryCatch","tryCatchOne","tryCatchList","tryCatch","compiler:::tryCompile"],"filenum":[1,1,1,1,null,1,1,1,1,1,1,1,null,1,1,1,1,1,1,1,null,1,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1],"linenum":[5,5,5,5,null,5,5,5,5,5,5,5,null,5,5,5,5,5,5,5,null,5,5,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,7],"memalloc":[22.5687026977539,31.3492965698242,44.8596649169922,54.0639877319336,63.9811019897461,63.9811019897461,40.7963027954102,60.7301177978516,26.9948654174805,47.5646438598633,16.6582870483398,37.938346862793,63.9640502929688,63.9640502929688,30.4710159301758,62.5281295776367,23.0977020263672,56.0793380737305,17.6883010864258,49.2125778198242,63.9970703125,63.9970703125,41.7478485107422,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078,58.8219757080078],"meminc":[0,8.78059387207031,13.510368347168,9.20432281494141,9.9171142578125,0,-23.1847991943359,19.9338150024414,-33.7352523803711,20.5697784423828,-30.9063568115234,21.2800598144531,26.0257034301758,0,-33.493034362793,32.0571136474609,-39.4304275512695,32.9816360473633,-38.3910369873047,31.5242767333984,14.7844924926758,0,-22.2492218017578,17.0741271972656,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"filename":["<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>"]},"interval":10,"files":[{"filename":"<expr>","content":"profvis::profvis({\n  get_tweet_id <- function() return(1);\n  has_next_tweet <- function(i) i < 10000;\n  k <- numeric(); i <- 1;\n  while (has_next_tweet(i)) {k <- c(k, get_tweet_id()); i <- i + 1;}\n  k <- numeric(); i <- 1;\n  while (has_next_tweet(i)) {k[i] <- get_tweet_id(); i <- i + 1;}\n})","normpath":"<expr>"}],"prof_output":"/tmp/RtmpxND8Ho/file3750c004812.prof","highlight":{"output":["^output\\$"],"gc":["^<GC>$"],"stacktrace":["^\\.\\.stacktraceo(n|ff)\\.\\.$"]},"split":"h"}},"evals":[],"jsHooks":[]}</script>

---
# drake
A promising package I wanted to use but never get to. "An R-focused pipeline toolkit for reproducibility and high-performance computing."

```r
plan &lt;- drake_plan(
  raw_data = readxl::read_excel(file_in("raw_data.xlsx")),
  data = raw_data %&gt;%
    mutate(Species = forcats::fct_inorder(Species)),
  hist = create_plot(data),
  fit = lm(Sepal.Width ~ Petal.Width + Species, data),
  report = rmarkdown::render(
    knitr_in("report.Rmd"),
    output_file = file_out("report.html"),
    quiet = TRUE
  )
)
make(plan)
```

---
# drake
![drake plan](https://camo.githubusercontent.com/e9cd15743788ea28d336848828f458aad86f1ad9/68747470733a2f2f646f63732e726f70656e7363692e6f72672f6472616b652f7265666572656e63652f666967757265732f67726170682e706e67)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
