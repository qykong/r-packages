---
title: "My favourite R packages"
subtitle: "generated by xaringan"
author: "Quyu Kong"
date: "2020/03/21"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

# Packages by categories

- Data processing:
  - `data.table` v.s. `tidyverse` (`tibble`, `dplyr`, `readr`, `magrittr`)
  - `purrr`
- Parallel computation:
  - `parallel::mclapply`
  - `future`
  - `furrr`, `future.batchtools`
- Visualization:
  - `ggplot2`, `cowplot`, `patchwork`
  - `shiny`
- Debugging:
  - `profvis`
- Reproducibility:
  - `drake`

```{r include=FALSE}
library(tidyverse)
library(data.table)
library(parallel)
library(furrr)
library(cowplot)
library(patchwork)
library(future.batchtools)
library(profvis)
library(magrittr)
```

---
class: inverse, center, middle

# data.table v.s. tidyverse
## More efficient v.s. better readability
---
# Tidyverse

`magrittr` provides the core of `tidyverse`'s better readability.
```{r eval=FALSE}
x %>% f()
f(x)
```
I found this particularly useful when playing around with data in the console
```{r}
unique(iris$Species)
unique(iris$Species) %>% length()
```

---
# Tidyverse

`tibble` is "a modern reimagining of the data.frame"

```{r}
iris <- iris %>% as_tibble()
iris %>% print(n=5)
```

`readr` implements APIs for reading from and writing to files
```{r include=TRUE,eval=FALSE}
write_csv(iris, file = 'iris.csv.gz')
read_csv(file = 'iris.csv.gz')
```

---
# Tidyverse

`dplyr` is a grammar of data manipulation.
```{r}
iris %>%
  filter(Species != 'setosa') %>%
  group_by(Species) %>%
  summarise_all(mean)
```

Recommended resource: https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf

---
# data.table

`data.table` is another reimplementation of `data.frame` and a data processing grammar designed with efficiency in mind at day 1.
It's basic syntax is

![data.table syntax](https://raw.githubusercontent.com/wiki/Rdatatable/data.table/pictures/syntax1.jpg)

However, this stopped from using `data.table` until I had to switch to it.

---
# data.table
The memory and data processing efficiency of `data.table`:
  - multi-threading processing
  - data processing by reference (the killer feature)
  
---
# data.table
```{r}
iris_dt <- as.data.table(iris)
iris <- iris %>%
  mutate(Sepal.Width = cut_interval(Sepal.Width, n = 3))
iris_dt[, Sepal.Width := cut_interval(Sepal.Width, n = 3)]
print(iris, n = 3)
print(iris_dt, n = 3)
```

---
# data.table
The file reader and writer from `data.table` also guarantee speed compared to `readr`.

|method   | 	                        max. memory | 	avg. time|
| ------------- |:-------------:| -----:|
|utils::read.csv + base::rbind |	21.70 GB |	8.13 m|
|readr::read_csv + purrr:map_dfr |	27.02 GB |	3.43 m|
|data.table::fread + rbindlist |	15.25 GB |	1.40 m|

More benchmarks: https://h2oai.github.io/db-benchmark/
Recommend reading: https://github.com/Rdatatable/data.table/wiki

---
# purrr from tidyverse

`purrr` is an alternative to R default `apply` function family (`lapply`, `vapply`, etc.). 
```{r}
iris %>%
  split(.$Species) %>%
  map(~lm(Petal.Length~Petal.Width, data = .x)) %>%
  map('coefficients')
```

---
# purrr from tidyverse
To me, one of the most important features is the type consistant API
```{r}
map_int(1:5, ~.x)
map_chr(letters, ~.x)
```

---
class: inverse, center, middle

# Parallel computation

---
# profvis
```{r}
profvis::profvis({
  get_tweet_id <- function() return(1);
  has_next_tweet <- function(i) i < 10000;
  k <- numeric(); i <- 1;
  while (has_next_tweet(i)) {k <- c(k, get_tweet_id()); i <- i + 1;}
  k <- numeric(); i <- 1;
  while (has_next_tweet(i)) {k[i] <- get_tweet_id(); i <- i + 1;}
})
```

